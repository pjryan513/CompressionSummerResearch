Research Article Title :
  Notes on Design and Implementation of Compressed Bit Vectors

Authors :
  Kesheng Wu, Ekow J. Otoo, Arie Shoshani, Henrik Nordberg

Date :
  September 27, 2001

Abstract :

  bitmap based indexing schemes work effectively in database applications

  compression schemes can be use to further improve their ^ effectiveness

  compression schemes can reduce the index size without increasing query processing time

  a bitmap index is stored as a collection of bitmaps
  the most frequent operations on these bitmaps are bitwise logical operations (AND, OR, NOT, XOR, SHIFT)

  to achieve this, reducing the size of indices is essential
  we want to be able to perform logical operations on the compressed bitmaps efficiently

  compression schemes (such as gzip) are effective in reducing the storage requirement, but don't support faster bitwise logical operations

  most specialized bitmap compression schemes are byte based, i.e., they access memory one byte at a time, and can not take full advantage of today's computing hardware that supports fast word operations.

  the paper introduces a number of word-based compression schemes with the expectation that they may support faster logical operations than the byte-based schemes

  word based schemes can be dozens of times faster than the byte based ones

  in many cases, word based compression bitmaps also perform bitwise logical operations faster than the uncompressed bitmaps

  Q&A for Abstract :
    what is the paper about?
    it is a study on a number of generic lossless compression algorithms and a number of specialized compression schemes
    it also serves as an introduction to a number of word-based compression schemes that may be preferable to byte-based compression schemes when run on modern hardware
    using compression algorithms and compression schemes, we are able to reduce the index size of a database without increasing query processing time
    the paper focuses on the type of compressed bit vectors that can support 'direct logical operations' which extinguish the necessity to uncompress bit vectors in order to perform logical operations (<- this tid-bit is found in the Introduction)

Part 1, Introduction :
  the term 'bitmap index' is used to refer to a broad category of indexing schemes that store their indices as bit sequences and use bitwise logical operations as athe primary means to extract answers from the indices

  'bitmap index' is effective for data warehouses and similar applications where the databases are read-mostly and the user queries usually involve more than one attribute


  the bitmap index allows the translation of queries...
    for example (using Figure 1), the query "R = B AND X < 4" can be translated to the following logical operations among 3 bit-sequences "b2 AND (b5 OR b6)"
    where :
      b2 : 01000010
      b5 : 00001010
      b6 : 10000000

    and the result of the aforementioned bitwise operations is a bit-sequence storing the result, in the above case 00000010 = result
    lastly, "if the ith bit of the result is 1, then the ith tuple of the database qualifies the query"

  there are well studied general purpose compression algorithms such as gzip and bzip2...
  ... however, these generic compression schemes are effective in compressing the bit sequences, but bitwise logical operations on the compressed bit sequences are much slower than operating on their uncompressed versions.

  since the logical operations are the crucial operations during query processing, the logical operations need to be as fast as possible.
  ^ to achieve this goal, we need to use compression schemes that support fast bitwise logical operations

  the computer data structure used to represent bit sequences is called a bit-vector (this term is used rather than bitmap to emphasis that the logical operations are a crucial part of the data structure)

  compression :
    a straightforward way of representing such a bit sequence is to use one bit of computer memory to represent one bit of the bit sequence, this is called 'literal bit vector'
    a simple idea of compressing a bit sequences is to break into a series of smaller sequences of consecutive identical bits, this is referred to as a 'fill'
    since each fill can be recorded with a counter representing its length plus one bit indicating the actual bit values, this representation may use less apce compared to the literal version, this is known as 'run-length encoding'
    if a run length is long enough, then the run-length encoding will use less space than the literal representation
    when performing a logical operation, working directly with the counters ensures that a minimum amount of computer memory is used to represent the operands and the result.
    compared to the alternative of decompressing the operands first then operating on the uncompressed bit vectors, operating directly on the compressed data needs less time because it avoids producing the intermediate uncompressed versions,
    this paper focuses on the type of compressed bit vectors that can support this type of direct logical operations

  the remainder of the paper will present 3 types of bit-vector schemes, namely, the literal scheme, byte based scheme, and word based scheme

Part 2, Literal Bit Vector and Generic Compression Schemes
  this section describes the literal version of the bit vector and explores how to use the generic lossless compression programs to reduce the size of the file

  remember, the literal version of the bit vector uses one bit of of computer memory to represent each of the bit sequences

  in a typical computer memory system, bits are organized into bytes and words...
  ... though a word typically contains several bytes most likely it takes the same amount of work to access either a word or a byte...
  ... in fact it may be slower to access a byte than to access a word, this is because most CPUs can only operate on data one word at a time

  the following algorithm describes how a bitwise logical operation can be performed.
  the subscripting operator [] and functions size(), back(), and push_back() are part of STL vector container.

  algorithm no.1, to perform a bitwise logical operation between two literal bit vectors x and y, and store the result in z.
  symbol ~ (tilde) denotes one of the three logical operations, AND, OR, or XOR

    for(i=0; i < x.vec.size();++i) {
      z.vec[i] = x.vec[i] ~ y.vec[i];
    }
    z.active.nbits = x.active.nbits;

    z.active.value = x.active.value ~ y.active.value;

    class activeWord {
      unsigned value;     // literal value of the active word
      unsigned nbits;     // number of bits in the active word
    };

    class literalBitVector {
      std::vector<unsigned> vec;    	A  // list of regular words
      activeWord active;              // the active word
    }


    table no.1 - performance information of the literal (lit) version of bit vector

    	no. of bits 		10^7		10^8		10^9
    	no. of byte 		1.25*10^6	1.25*10^7	1.25^10^8		 
    		 
    	read only (sec)		0.020		0.195		2.00		(1) time to read a file one page at a time and discard the content, marked 'read only'			
    	read to bit vector 	0.048		0.490		4.89 		(2) time to read a file and form a bit vector from the file content, marked 'read to bit vector'
    	logical operation 	0.010		0.127		1.280		(3) time to perform a single bitwise logical operation between two bit vectors

    	table 1 contains three timing results 
    		(1) time to read a file one page at a time and discard the content, marked 'read only' 
    		(2) time to read a file and form a bit vector from the file content, marked 'read to bit vector' 
    		(3) time to perform a single bitwise logical operation between two bit vectors -> note, in this implementation, the three logical operations AND, OR and XOR, take the same amount of time
    		the timing results reported in table 1 are recored using getrusage function 	



    the logical operation time on two 10^8 bit sequences is more than 10 times that on two 10^7 bit sequences because the data involved in the shorter bit sequences can fit into the 4mb data cache of the processor, but not the larger ones

    when used to represent the bitmap indices, these bit vectors are much more likely to be read than be written

    reading a file and forming a bit vector takes about twice as long as simply reading the file because we need to copy the content into the vector container

    replacing the stl vector with a custom data structure that avoids this copying would remove most of the over head in forming the literal bit vector

    "Ideally, a good compressed bit vector should use less memory (no. of bytes) and perform logical operations in less time than this literal scheme" - page 6

    three compression routines that are potential candidates for use :
    	gzip
    		this is one of the most popular compression utilities
    		it uses lempel-ziv coding (lz77) which is known to be asymptotically optimal
    		it is freely available and it also comes with a set of easy to use API (zlib) for performing bitwise logical operations

    	bzip2
    		this uses borrows-wheeler text compression and huffman coding
    		its documentation claims that it is often faster than gzip and even compresses better than gzip in many cases
    		it offers similar API as zlib

    	lzop
    		this one implements a modified version of the lempel-ziv scheme
    		the decompresser is very efficient and it is able to achieve a significant fraction of the speed of memcpy() function
    		this makes it particularly attractive because the decompresser is likely to be used more often than the compressor

    "When the bit density is low, the compression programs are very effective; the compressed files are much smaller than uncompressed files." - page 6

    as the bit density increases, compression becomes less effective


    figure 5 (page 8) and table 2 (page 9) show timing results of two ways of processing the compressed bit vector files and performing bitwise logical operations on them
    'two step approach', the first approach does this in two steps :
    	(1) read two files containing two operands of the logical operation and decompress the data into two literal bit vectors
    	(2) perform the logical operations on these two bit vectors

    the second approach reads the two files one piece at a time using zlib functions, perform the bitwise operation on the portion of data and store the results in a bit vector 
    this is marked as the 'one-step' approach in figure 5 and table 2

    in some cases, it may be useful to use the two step approach and store the bit vectors in memory so that the later operations do not need to read the files again


	QUESTION
	    (page 4) why is the following suggestion true?  'though a word typically contains several bytes, most likely it takes the same amount of work to access either a word or a byte'
	    what is an STL vector container? [resource no.27]


Part 3, Byte Based Schemes
	when used to store images, the smallest unit of data accessed by most image formats is a byte
	for this reason, most existing bitmap compression schemes are byte based


	3.1 PackBits (PAC)

		this is a simple scheme designed for compressing bitmap images
		the PackBit scheme first divides a long bit sequence into bytes and then groups the consecutive bytes into two types of runs :
			literal runs
				a literal run can have 0-127 bytes of arbitrary values
				a header byte is used to indicate the run length, i.e., the number of bytes in the run

			fill runs
				a fill run can represent 2-129 bytes of the same value 
				it is an unsigned integer that is equal to the run plus 126

		this scheme does not require all the bits in the fill to be the same, only that all the bytes by the same
		because each run of PackBits represents multiple of 8 bits, we say this scheme is byte aligned

		Algorithm 2
			to append a literal byte to a list of regular encoded bytes stored in a vector container called vec
			the active byte is used as a place holder for this literal byte
			when the bit vector is empty, the vector container vec is empty {
				set the first byte in vec to be 1 (vec.push_back(1))
				the second byte to be the value of the active byte (vec.push_back(active.value))
				lastHeader = 0
			} otherwise {
				// see page 7 for algorithm 2
			}


		analysis of PackBits (PAC)
			if all bytes are the same, this scheme uses two bytes to represent every 129 bytes
			the best case compression ratio is 0.0155
			if all bytes are literal bytes, it uses 128 bytes to represent every 127 literal bytes, a 0.8% overhead
			if a bit sequence consists of two bytes that are the same followed by a third byte that is different from the first two, this scheme needs for bytes to represent these three bytes -> this worst case overhead is 33%


		Algorithm 3
			given two packbits bit vectors x and y, perform an arbitrary bitwise logical operation (denoted ~) to produce a bit vector z

			run xrun, yrun
			xrun.it = x.vec.begin()
			yrun.it = v.vec.begin()
			// ... see page 11 for algorithm 3 

	3.2 Byte-aligned Bitmap Code (BBC)
		the original version of this scheme was invented by G.Antoshenkov
		bitwise logical operations on sparse bit vectors are usually faster using BBC coding than using gzip compression, it may even be faster using the literal bit scheme 

		similar to packbits, bbc scheme first organizes bits into bytes but all runs of bbc are of the form of a fill followed by some literal bytes called a tail

		bbc encoding has a number of different 'run types' -> (see page 13, 14 for run-types)

		analysis of byte-aligned bitmap code (bbc)
			bitwise logical operations perform very fast, comparably fast to literal bit schemes
			if the majority of the bits are the same, bbc can be very compact
			if all bits are the same, it only needs a few bytes to represent the bit sequence
			if the bit vector cannot be compressed at all, BBC code uses 16 bytes to represent every 15 literal bytes, a 6.7% overhead

	3.3 PackBits with multibyte counter (PBM)
		TODO
	3.4 Performance
		in a comparison (page 16) on the three logical operations and time that the bit vectors require for each ->
			'overall the three logical operations have similar performance characteristics. The AND operation takes slightly less time compared to the other two logical operations especially when the bit densities are low because the resulting bit vector has lower bit density than that of the other two'


Part 4, Word Based Schemes
	most general purpose computer access memory by words even if only a single byte or bit is requested
		QUESTION ^ is this still true in 2017?

	this section describes four different word based schemes...
		hybrid run-length encoding (HRL)
		word-aligned hybrid run-length encoding (WAH)
		packed word code (PWC)
		word-aligned bitmap code (WBC)

	analysis of the word based schemes
		PWC usually uses more space than the other three
		compression ratios :
			hrl 	0.0055
			wah 	0.0055
			pwc 	0.0083
			wbc 	0.0055

		overall, hrl takes the longest time to perform the same operation and wah usually uses the least amount of time
		in many cases wah needs only 50-70% of the time used by pwc and wbc 
		when bit densities are high , logical operations on two hrl bit vectors take almost 40 times longer than performing the same operations using any one of the three word-alignment based schemes
		when bit densities are high, logical operations on two HRL bit vectors take almost 40 times longer than performing the same operations using an one of the three word-aligned schemes 
		this clearly demonstrates the importance of maintaining word-alignment in the word based scheme

		compared to word based schemes
			at bit density 10^-4, operating with pwc and wbc bit vectors uses about the same amount of time as on bbc bit vectors even though the word based schemes need to go through more memory than the byte based versions
			logical operations on two wah bit vectors needs about half the time of that on two bbc bit vectors
			as the bit density increases, the time used by the word based schemes grow much slower than that of the byte based schemes

			when bit density is close to 0.5, where the word based schemes and byte based schemes use about the same amount of space (bbc) takes about 34 seconds to perform one bitwise logical operation on one billion bits
			in many cases, the byte-aligned versions take about four times as long to perform a logical operation than the word-aligned versions

			among the three word-aligned bit vectors in terms of storage requirement, pwc does not compress as well as wbc or wah
			in terms of bitwise logical operation speed, pwc is not any faster than the other two

		page 28, 'we see that almost two thirds of the total reading time is actually spent on forming the bit vector, if we can avoid forming the bit vector during bitwise logical operation, we can reduce the total execution time'

		page 29, 'since moving one byte takes about the same amount of time as moving one word, it is clear that inserting the same number of byte (one byte at a time) takes four times as long (as moving a word)'

		page 29, 'overall, working with WAH bit vectors takes the least amount of time. Operating on BBC bit vectors takes about 60-300% more time than operating on WAH bit vectors'

		page 29, 'the difference between time used by BBC scheme and WAH scheme increases as bit densities increase'

		comparing between WBC and WAH, when bit density is low, WAH is slightly better - the time difference is less than %25; when bit density is high, the two schemes use about the same amount of time

		the advantage of using word based schemes is that we might have faster bitwise logical operations

Part 5, Observations and Analyses
	this section is used to analyze the observations made by the researchers to see whether they can be applied and the principles generalized

	5.1 Alignment is good for logical operations
	5.2 Word-aligned bit vectors are faster
	5.3 Sizes of operands determine speed
	5.4 Recognizing the incompressible is useful
	5.5 Separated decompression is slow
	5.6 STL vector container is slow for IO
	5.7 Putting it together

Part 6, Summary and Future Work
	